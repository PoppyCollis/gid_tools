# gid_tools/envs/feedback.py
"""
Environment for computing reward feedback on images generated by a diffusion model.
"""
import torch
import numpy as np
from typing import Callable, Dict, Optional, Union

def pixel_area_tensor(img: torch.Tensor, threshold: float = 0.0) -> int:
    """
    Compute the 2D area (number of 'on' pixels) of a Torch image in [-1,1].
    Assumes img.shape = [1,H,W] or [H,W].
    Counts pixels > threshold.
    """
    # squeeze channel if present
    if img.dim() == 3:
        img = img.squeeze(0)
    mask = img > threshold
    return int(mask.sum().item())


class ToolRewardEnv:
    """
    ToolRewardEnv applies reward functions to images generated by a diffusion model.

    Methods
    -------
    - register_reward(name, fn): register a custom reward function
    - compute(img, method=None, **kwargs): compute reward using the specified method
    """
    def __init__(self, default_method: str = 'pixel_area'):
        # registry of reward functions
        self._rewards: Dict[str, Callable[..., Union[int, float]]] = {}
        # register built-in methods
        self.register_reward('pixel_area', pixel_area_tensor)
        # set default
        self.default_method = default_method

    def register_reward(self, name: str, fn: Callable[..., Union[int, float]]):
        """
        Register a new reward function.

        Parameters
        ----------
        name : str
            Name of the reward function.
        fn : callable
            Function that takes (img: torch.Tensor, **kwargs) and returns a numeric reward.
        """
        if not callable(fn):
            raise ValueError(f"Reward function for '{name}' must be callable.")
        self._rewards[name] = fn

    def list_methods(self) -> list:
        """
        List all registered reward methods.
        """
        return list(self._rewards.keys())

    def compute(self, img: torch.Tensor, method: Optional[str] = None, **kwargs) -> Union[int, float]:
        """
        Compute the reward for a given image using the specified method.

        Parameters
        ----------
        img : torch.Tensor
            Image tensor from the diffusion model.
        method : str, optional
            The name of the reward function to use. Defaults to None, which uses the default method.
        **kwargs
            Additional arguments to pass to the reward function.

        Returns
        -------
        int or float
            The computed reward.
        """
        if method is None:
            method = self.default_method
        if method not in self._rewards:
            raise KeyError(f"Reward method '{method}' not found. Available methods: {self.list_methods()}")
        fn = self._rewards[method]
        return fn(img, **kwargs)
